
# # Sentiment Analysis
# 

# ## NLTK's VADER module
# VADER is an NLTK module that provides sentiment scores based on words used ("completely" boosts a score, while "slightly" reduces it), on capitalization & punctuation ("GREAT!!!" is stronger than "great."), and negations (words like "isn't" and "doesn't" affect the outcome).
# 

# **Download the VADER lexicon.** You only need to do this once.

# In[10]:


import nltk
nltk.download('vader_lexicon')


# In[11]:


from nltk.sentiment.vader import SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()


# VADER's `SentimentIntensityAnalyzer()` takes in a string and returns a dictionary of scores in each of four categories:
# * negative
# * neutral
# * positive
# * compound *(computed by normalizing the scores above)*

# In[12]:


a = 'This was a good movie.'
sid.polarity_scores(a)


# In[13]:


a = 'This was the best, most awesome movie EVER MADE!!!'
sid.polarity_scores(a)


# In[14]:


a = 'This was the worst film to ever disgrace the screen.'
sid.polarity_scores(a)


# ## Use VADER to analyze Amazon Reviews
# For this exercise we're going to apply `SentimentIntensityAnalyzer` to a dataset of 10,000 Amazon reviews. Like our movie reviews datasets, these are labeled as either "pos" or "neg". At the end we'll determine the accuracy of our sentiment analysis with VADER.

# In[15]:


import numpy as np
import pandas as pd
df = pd.read_csv('..//amazonreviews.tsv', sep='\t')
df.head()


# In[16]:


df['label'].value_counts()


# ## Let's run the first review through VADER

# In[17]:


sid.polarity_scores(df.loc[0]['review'])


# In[18]:


df.loc[0]['label']


# Great! Our first review was labeled "positive", and earned a positive compound score.

# ## Adding Scores and Labels to the DataFrame
# In this next section we'll add columns to the original DataFrame to store polarity_score dictionaries, extracted compound scores, and new "pos/neg" labels derived from the compound score. We'll use this last column to perform an accuracy test.

# In[19]:


df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))

df.head()


# In[20]:


df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])

df.head()


# In[21]:


df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')

df.head()


# ## Report on Accuracy
# Finally, we'll use scikit-learn to determine how close VADER came to our original 10,000 labels.

# In[22]:


from sklearn.metrics import accuracy_score,classification_report,confusion_matrix


# In[23]:


accuracy_score(df['label'],df['comp_score'])


# In[24]:


print(classification_report(df['label'],df['comp_score']))


# In[25]:


print(confusion_matrix(df['label'],df['comp_score']))

