# In[ ]:


# Perform imports and load the dataset:
import numpy as np
import pandas as pd

df = pd.read_csv('..//smsspamcollection.tsv', sep='\t')
df.head()


# In[ ]:


df.isnull().sum()


# ## Take a quick look at the *ham* and *spam* `label` column:

# In[ ]:


df['label'].value_counts()


# ## Split the data into train & test sets:

# In[ ]:


from sklearn.model_selection import train_test_split

X = df['message']  # this time we want to look at the text
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)


# In[ ]:


from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()

X_train_counts = count_vect.fit_transform(X_train)
X_train_counts.shape


# ## Build a Pipeline
# 

# In[ ]:


from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC

text_clf = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', LinearSVC()),
])
  


# In[ ]:


# Feed the training data through the pipeline
text_clf.fit(X_train, y_train)


# ## Test the classifier and display results

# In[ ]:


# Form a prediction set
predictions = text_clf.predict(X_test)


# In[ ]:


from sklearn import metrics


# In[ ]:


# Report the confusion matrix
print(metrics.confusion_matrix(y_test,predictions))


# In[ ]:


# Print a classification report
print(metrics.classification_report(y_test,predictions))


# In[ ]:


# Print the overall accuracy
print(metrics.accuracy_score(y_test,predictions))



